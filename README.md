# ğŸ¦  AI-Powered Disease Outbreak Early Warning System

A comprehensive MLOps pipeline that collects real-time health signals, processes data, and predicts potential disease outbreak hotspots before they escalate.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

## ğŸ¯ Problem Statement

Outbreaks of diseases like dengue, malaria, and influenza often spread silently before authorities detect them. This delays medical response, overwhelms hospitals, and risks thousands of lives. Traditional monitoring relies heavily on hospital data alone, which is often delayed.

## âœ¨ Features

- **Real-time Monitoring**: Track disease indicators across multiple data sources
- **Predictive Analytics**: Machine learning models to forecast outbreak risks
- **Interactive Dashboard**: Visualize disease trends and predictions
- **Alert System**: Get notified about potential outbreaks
- **Data Versioning**: Track changes in data and models over time
- **Scalable Infrastructure**: Deploy on-premises or in the cloud

## ğŸš€ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Sources  â”‚    â”‚  Data Pipeline  â”‚    â”‚  ML Pipeline    â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Social Media  â”‚â”€â”€â”€â–¶â”‚ â€¢ Kafka         â”‚â”€â”€â”€â–¶â”‚ â€¢ MLflow        â”‚
â”‚ â€¢ Hospital Logs â”‚    â”‚ â€¢ Spark         â”‚    â”‚ â€¢ XGBoost       â”‚
â”‚ â€¢ Weather Data  â”‚    â”‚ â€¢ DBT           â”‚    â”‚ â€¢ LSTM          â”‚
â”‚ â€¢ Health APIs   â”‚    â”‚ â€¢ Redshift      â”‚    â”‚ â€¢ Prophet       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                       â”‚
                                â–¼                       â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚  FastAPI API    â”‚    â”‚  Monitoring     â”‚
                       â”‚                 â”‚    â”‚                 â”‚
                       â”‚ â€¢ Predictions   â”‚    â”‚ â€¢ Prometheus    â”‚
                       â”‚ â€¢ Alerts        â”‚    â”‚ â€¢ Grafana       â”‚
                       â”‚ â€¢ Dashboard     â”‚    â”‚ â€¢ Alerting      â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ—ï¸ Project Structure

```
disease-mlops-project/
â”œâ”€â”€ data/                      # Data storage and samples
â”‚   â”œâ”€â”€ raw/                  # Raw data files
â”‚   â””â”€â”€ processed/            # Processed data files
â”œâ”€â”€ infrastructure/           # Terraform and Kubernetes configs
â”œâ”€â”€ ml/                       # Machine learning models and pipelines
â”‚   â”œâ”€â”€ train_models.py       # Model training script
â”‚   â””â”€â”€ monitor_model.py      # Model monitoring
â”œâ”€â”€ pipelines/                # Data processing pipelines
â”œâ”€â”€ api/                      # FastAPI service
â”‚   â”œâ”€â”€ main.py               # API entry point
â”‚   â””â”€â”€ models.py             # ML model definitions
â”œâ”€â”€ dashboard/                # Streamlit dashboard
â”‚   â””â”€â”€ app.py               # Dashboard application
â”œâ”€â”€ frontend/                 # Modern web interface (HTML/CSS/JS)
â”œâ”€â”€ monitoring/               # Prometheus and Grafana configs
â”œâ”€â”€ docker/                   # Docker configurations
â”‚   â””â”€â”€ docker-compose.yml    # Service definitions
â”œâ”€â”€ scripts/                  # Utility scripts
â”‚   â””â”€â”€ load_sample_data.py   # Sample data loader
â””â”€â”€ docs/                     # Documentation
    â””â”€â”€ DATA_VERSIONING.md    # Data versioning strategy
```

## ğŸš€ Quick Start

### Prerequisites

- Docker and Docker Compose
- Python 3.8+
- PostgreSQL 13+
- Redis 6+

### Environment Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/disease-mlops-project.git
   cd disease-mlops-project
   ```

2. **Set up environment variables**
   ```bash
   cp .env.example .env
   # Edit .env with your configuration
   ```

3. **Install Python dependencies**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   pip install -r requirements.txt
   ```

### Running with Docker (Recommended)

1. **Start all services**
   ```bash
   docker-compose up -d
   ```

   This will start:
   - API service (port 8000)
   - PostgreSQL database
   - Redis cache
   - MLflow tracking server (port 5000)
   - Prometheus (port 9090)
   - Grafana (port 3000)

2. **Verify services**
   - API Docs: http://localhost:8000/api/docs
   - MLflow UI: http://localhost:5000
   - Grafana: http://localhost:3000 (admin/admin)

3. **Load sample data**
   ```bash
   docker-compose exec api python scripts/load_sample_data.py
   ```

### Running Locally

1. **Start database services**
   ```bash
   docker-compose up -d postgres redis
   ```

2. **Run the API**
   ```bash
   cd api
   uvicorn main:app --reload
   ```

3. **Run the dashboard**
   ```bash
   cd dashboard
   streamlit run app.py
   ```

## ğŸ“Š Using the System

### Making Predictions

```python
import requests

url = "http://localhost:8000/api/predict"
data = {
    "location": {"city": "Mumbai", "region": "Maharashtra"},
    "disease_name": "Dengue",
    "weather_conditions": {
        "temperature": 30.5,
        "humidity": 75.0,
        "rainfall": 10.2
    },
    "population_density": 20000,
    "historical_cases": [
        {"date": "2023-01-01", "cases": 5},
        {"date": "2023-01-02", "cases": 7}
    ],
    "social_media_mentions": 45
}

response = requests.post(url, json=data)
print(response.json())
```

### API Endpoints

- `GET /` - Health check
- `POST /api/predict` - Get outbreak risk prediction
- `GET /api/data/cases` - Get historical case data
- `GET /api/data/weather` - Get weather data
- `GET /api/metrics` - Prometheus metrics

## ğŸ§ª Running Tests

```bash
# Install test dependencies
pip install -r requirements-test.txt

# Run all tests
pytest tests/

# Run specific test file
pytest tests/test_api.py -v

# Run with coverage report
pytest --cov=api --cov=ml tests/
```

## ğŸ“ˆ Monitoring and Logging

- **Prometheus**: http://localhost:9090
- **Grafana**: http://localhost:3000
- **MLflow**: http://localhost:5000

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“š Documentation

For detailed documentation, please see the [docs](docs/) directory.

## ğŸ™ Acknowledgments

- Healthcare workers and data scientists working on disease prevention
- Open-source communities for their invaluable tools and libraries
- Docker and Docker Compose
- Python 3.9+
- Terraform
- kubectl (for Kubernetes deployment)

### 1. Start Local Development Environment
```bash
docker-compose up -d
```

### 2. Initialize Infrastructure
```bash
cd infrastructure
terraform init
terraform apply
```

### 3. Start Data Pipeline
```bash
cd pipelines
python start_kafka_producer.py
python start_spark_streaming.py
```

### 4. Train ML Models
```bash
cd ml
python train_models.py
```

### 5. Start API Service
```bash
cd api
uvicorn main:app --reload
```

### 6. Launch Dashboard
```bash
cd dashboard
streamlit run app.py
```

### 7. Launch Modern Web Frontend (Optional)
```bash
cd frontend
python server.py
```

Then open your browser to: **http://localhost:3000**

The frontend provides a professional web interface with:
- ğŸ¯ Interactive dashboard with real-time metrics and risk maps
- ğŸ”® AI prediction interface for outbreak risk assessment  
- ğŸš¨ Alert management with severity classification
- ğŸ“Š Advanced analytics with customizable time ranges
- ğŸ“± Responsive design for all devices

## ğŸ“Š Features

- **Real-time Data Ingestion**: Kafka streams for social media, hospital logs, and weather data
- **Data Processing**: Apache Spark for streaming data and DBT for batch transformations
- **ML Pipeline**: XGBoost, LSTM, and Prophet models with MLflow tracking
- **API Service**: FastAPI endpoints for predictions and alerts
- **Monitoring**: Prometheus metrics and Grafana dashboards
- **Alerting**: Automated notifications for outbreak risks and system issues
- **Dashboard**: Real-time outbreak risk visualization by region

## ğŸ”§ Technologies Used

- **Data Pipeline**: Apache Kafka, Apache Spark, DBT, Amazon Redshift
- **ML**: MLflow, XGBoost, TensorFlow, Prophet
- **API**: FastAPI, Docker, Kubernetes
- **Monitoring**: Prometheus, Grafana, AlertManager
- **Infrastructure**: Terraform, AWS
- **Dashboard**: Streamlit
- **Frontend**: HTML5, CSS3, JavaScript, Chart.js, Leaflet Maps

## ğŸ“ˆ Impact

This system enables:
- Early detection of disease outbreaks
- Proactive resource allocation
- Faster medical response
- Prevention of healthcare system overload
- Data-driven public health decisions

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

MIT License - see LICENSE file for details
